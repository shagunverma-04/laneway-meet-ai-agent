# ğŸ¥ Laneway Meet AI Agent

A powerful, AI-driven web application designed to streamline post-meeting workflows. This tool automatically ingests meeting recordings, generates accurate transcripts, identifies action items, and assigns them to team members.

![Status](https://img.shields.io/badge/Status-Active-success)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/Backend-FastAPI-009688)
![Redis](https://img.shields.io/badge/Cache-Redis-red)

## âœ¨ Features

- **ğŸš€ Smart Transcription**: Uses **Faster-Whisper** for high-performance, local speech-to-text conversion. Capable of running heavily optimized inference on CPU/GPU.
- **âš¡ Intelligent Caching**: Integrated **Redis** caching layer ensures that previously processed files are retrieved instantly, saving time and compute resources.
- **ğŸ“ Action Item Extraction**: Leverages LLMs (OpenAI GPT) to parse transcripts and extract concrete tasks, deadlines, and owners.
- **ğŸ¨ Modern UI**: A sleek, responsive dark-mode web interface for easy file uploads and result viewing.
- **ğŸ“‚ Wide Format Support**: Ingests `mp4`, `wav`, and other common media formats via `ffmpeg`.

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI (Python)
- **Frontend**: Vanilla HTML5 / CSS3 (Responsive Design)
- **AI/ML**: 
  - `faster-whisper` (Local Transcription)
  - `openai-gpt` (Task Extraction)
- **Infrastructure**:
  - Redis (Caching)
  - FFmpeg (Audio Processing)
  - Docker (Containerization)

## ğŸš€ Getting Started

### Prerequisites

1.  **Python 3.10+** installed.
2.  **FFmpeg** installed and added to system PATH.
3.  **Redis Server** running locally (e.g., via Memurai on Windows or Docker).

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/shagunverma-04/laneway-meet-ai-agent.git
    cd laneway-meet-ai-agent
    ```

2.  **Set up Virtual Environment:**
    ```bash
    python -m venv .venv
    # Windows
    .venv\Scripts\activate
    # Mac/Linux
    source .venv/bin/activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure Environment:**
    Create a `.env` file in the root directory:
    ```env
    OPENAI_API_KEY=sk-your-api-key-here
    ```

### Running the Application

1.  **Ensure Redis is running** (Default: localhost:6379).
2.  **Start the Server:**
    ```bash
    python app.py
    ```
3.  **Access the UI:**
    Open your browser and navigate to `http://localhost:8000`.

## ğŸ³ Deployment

The application is container-ready and includes a `Dockerfile`.

### Deploying to Render/Cloud
1.  **Database**: Ensure you have a Redis instance available (e.g., Render Redis).
2.  **Environment Variables**: Set `OPENAI_API_KEY` and any Redis configuration variables needed.
3.  **Build Command**: `pip install -r requirements.txt`
4.  **Start Command**: `python app.py` (or `uvicorn app:app --host 0.0.0.0 --port $PORT`)

## ğŸ“‚ Project Structure

- `app.py`: Main FastAPI application and API endpoints.
- `scripts/transcribe.py`: Logic for Whisper transcription (supports Local & API).
- `scripts/extract_tasks.py`: LLM-based task extraction logic.
- `index.html` & `styles.css`: Frontend user interface.
- `requirements.txt`: Project dependencies.


